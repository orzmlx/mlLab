---
title: "Block2 Group A2"
author: |
  liume102@student.liu.se  
  hanxi898@student.liu.se  
  xiali125@student.liu.se
date: "2024-11-26"
output:
  pdf_document: 
    latex_engine: xelatex
    number_sections: true
    fig_width: 7
    highlight: tango
    toc: true
editor_options: 
  markdown: 
    wrap: 72
---
```{r setup, include=FALSE}
library(caret)  # for data partitioning
library(rpart)
data <- read.csv(
  'bank-full.csv',
  sep = ";",
  header = TRUE,
  stringsAsFactors = TRUE
)
data <- data[, !names(data) %in% c("duration")]

# Partition the data into training (40%), validation (30%), and test (30%)
set.seed(123)  # for reproducibility
trainIndex <- createDataPartition(data$y, p = 0.4, list = FALSE)  # replace target_variable with your target variable name

train_data <- data[trainIndex, ]
remaining_data <- data[-trainIndex, ]

validationIndex <- createDataPartition(remaining_data$y, p = 0.5, list = FALSE)
validation_data <- remaining_data[validationIndex, ]
test_data <- remaining_data[-validationIndex, ]
```


```{r}
tree_default <- rpart(y ~ ., data = train_data, method = "class")

# Predict on training and validation data
train_pred_default <- predict(tree_default, train_data, type = "class")
validation_pred_default <- predict(tree_default, validation_data, type = "class")

# Calculate misclassification rates
train_misclassification_default <- mean(train_pred_default != train_data$y)
validation_misclassification_default <- mean(validation_pred_default != validation_data$y)

# Print misclassification rates
cat("Training Misclassification Rate (Default):", train_misclassification_default, "\n")
cat("Validation Misclassification Rate (Default):", validation_misclassification_default, "\n")
```


```{r}
# Fit decision tree with minimum node size 7000
tree_node_size_7000 <- rpart(y ~ ., data = train_data, method = "class", control = rpart.control(minsplit = 7000))

# Predict on training and validation data
train_pred_node_size_7000 <- predict(tree_node_size_7000, train_data, type = "class")
validation_pred_node_size_7000 <- predict(tree_node_size_7000, validation_data, type = "class")

# Calculate misclassification rates
train_misclassification_node_size_7000 <- mean(train_pred_node_size_7000 != train_data$y)
validation_misclassification_node_size_7000 <- mean(validation_pred_node_size_7000 != validation_data$y)

# Print misclassification rates
cat("Training Misclassification Rate (Node Size = 7000):", train_misclassification_node_size_7000, "\n")
cat("Validation Misclassification Rate (Node Size = 7000):", validation_misclassification_node_size_7000, "\n")
```
#3 using training and validataion sets to choose the optimal tree depth in model:
# study the trees up to 50 leaves
```{r}
tree_deviance_0005 <- rpart(y ~ ., data = train_data, method = "class", control = rpart.control(minsplit = 20, cp = 0.0005))

# Predict on training and validation data
train_pred_deviance_0005 <- predict(tree_deviance_0005, train_data, type = "class")
validation_pred_deviance_0005 <- predict(tree_deviance_0005, validation_data, type = "class")

# Calculate misclassification rates
train_misclassification_deviance_0005 <- mean(train_pred_deviance_0005 != train_data$y)
validation_misclassification_deviance_0005 <- mean(validation_pred_deviance_0005 != validation_data$y)

# Print misclassification rates
cat("Training Misclassification Rate (Deviance = 0.0005):", train_misclassification_deviance_0005, "\n")
cat("Validation Misclassification Rate (Deviance = 0.0005):", validation_misclassification_deviance_0005, "\n")
```


#4 estimate the confusion matrix, accuracy and F1 score for the test data by using the optimal model from step 3
finalTree = prune.tree(fit_dev, best = 13)
Yfit = predict(finalTree, newdata = test, type = "class")
#confusion matrix
conf_mat <- table(test$y, Yfit)
#accuracy
accuracy = sum(diag(conf_mat))/ dim(test)[1]
#F1 score

true_positives <- conf_mat[2, 2]
false_positives <- conf_mat[1, 2]
false_negatives <- conf_mat[2, 1]

precision <- true_positives / (true_positives + false_positives)
recall <- true_positives / (true_positives + false_negatives)
f1_score <- 2 * (precision * recall) / (precision + recall)

#5 perform a decision tree classification of the test data with the following loss matrix, and
#report the confusion matrix for the test data
loss_matrix = matrix(c(0, 1, 5, 0), 2, 2)
matrixtree = prune.tree(fit_dev, loss = loss_matrix)
Yfit_mat = predict(matrixtree, newdata = test, type = "class")

conf_mat_mat <- table(test$y, Yfit_mat)
#accuracy
accuracy_mat = sum(diag(conf_mat_mat)) / dim(test)[1]
#F1 score

true_positives_mat <- conf_mat_mat[2, 2]
false_positives_mat <- conf_mat_mat[1, 2]
false_negatives_mat <- conf_mat_mat[2, 1]

precision_mat <- true_positives_mat / (true_positives_mat + false_positives_mat)
recall_mat <- true_positives_mat / (true_positives_mat + false_negatives_mat)
f1_score_mat <- 2 * (precision_mat * recall_mat) / (precision_mat + recall_mat)

#6 use the optional tree and a logistic regression model to classify the test data
# by using the following principle








